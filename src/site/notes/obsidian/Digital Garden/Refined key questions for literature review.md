---
{"dg-publish":true,"permalink":"/obsidian/digital-garden/refined-key-questions-for-literature-review/","created":"2025-08-13T16:41:23.689+01:00","updated":"2025-08-14T10:09:39.849+01:00"}
---

<a href="https://anapoly.co.uk/labs">Anapoly Notebook</a> | [[obsidian/Digital Garden/Digital Garden\|Digital Garden]] 

# Refined Key Questions for Literature Review

I asked the AI to clarify how the key questions should be refined. It explained that the **refinement** wasn’t to change the _scope_ of my existing Key Questions in the [[obsidian/Digital Garden/project Instructions – AI & Young People\|project Instructions – AI & Young People]], but to make them **operational** for the literature review, so they act as sorting and tagging criteria rather than just big-picture guiding questions. Right now, in my [[obsidian/Digital Garden/project Instructions – AI & Young People\|project Instructions – AI & Young People]], the Key Questions are strategic:

> - What are the main temptations for young people to outsource their thinking to AI?>     
> - What dangers arise from these temptations…?     

For the initiation phase, we can turn these into **research-ready questions** that:

1. Are **specific enough** to guide what we look for in each source.    
2. Naturally map onto table columns, tags, and the temptation–danger–mitigation chain.    
3. Cover both internal and external sources in the same framework.

The AI offered the following **operational rewrite** of the Key Questions, keeping the original intent but breaking each into practical sub-questions for source capture. They seemed very good, so I accepted them pending more detailed consideration. The intention is to use these as the **capture criteria** for each source, so that the literature review will naturally produce well-structured content for the later analysis and synthesis phases.

---

### **1. Temptations to Outsource Thinking**

**Strategic:** What are the main temptations for young people to outsource their thinking to AI?  
**Operational Sub-Questions:**

- What specific _behaviours_ are described as outsourcing thinking?    
- What _motivations_ or needs lead to these behaviours? (e.g., speed, convenience, perceived accuracy, avoiding effort, social/peer influence, anxiety about performance)    
- What _contexts_ are these behaviours most associated with? (e.g., academic writing, decision-making, problem-solving, creative work)    
- Which demographic subgroups are mentioned? (university students, school pupils, early-career professionals)    
- Are there differences in temptation between disciplines or fields of study?    

---

### **2. Dangers Arising from These Temptations**

**Strategic:** What dangers arise from these temptations, and how do they manifest differently for university students?  
**Operational Sub-Questions:**

- Which _capabilities_ or _habits_ are at risk? (e.g., critical thinking, independent research, reflective judgement, creativity)    
- How do these dangers manifest in academic or personal development?    
- Are there specific _examples or case studies_ in the source?    
- Are dangers _short-term_ (e.g., reduced learning in a course) or _long-term_ (e.g., dependency, professional unpreparedness)?    
- What _differences_ are observed between younger students and university students?    
- Are dangers framed as _direct consequences_ of AI use or _indirect effects_ via cultural or institutional changes?
    

---

### **3. Nature of “Responsible AI Use”**

**Strategic:** What constitutes “responsible AI use” in this context?  
**Operational Sub-Questions:**

- How does the source define or describe “responsible” use?    
- What _practices_ or _habits_ are recommended? (e.g., fact-checking, combining AI with human review, limiting use to certain stages of work)    
- Are there any _ethical frameworks_ or _guidelines_ referenced?    
- How does the source suggest users balance AI assistance with independent thinking?
    

---

### **4. Mitigation of Dangers Through Responsible AI Use**

**Strategic:** Can responsible AI use mitigate these dangers effectively, and if so, how?  
**Operational Sub-Questions:**

- Which specific dangers are addressed by responsible use in the source?    
- What _mechanisms_ or _strategies_ are proposed? (e.g., education, tool design, institutional policy)   
- Is there evidence of effectiveness? (research findings, pilot programmes, anecdotal reports)    
- What are the _limits_ of responsible use — where might dangers persist despite good practice?    
- Does the source propose _systemic changes_ (e.g., curriculum redesign) or focus on _individual responsibility_?    

---



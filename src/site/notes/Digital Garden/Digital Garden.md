---
{"dg-publish":true,"permalink":"/digital-garden/digital-garden/","tags":["gardenEntry"],"created":"2025-08-11T21:46:53.866+01:00","updated":"2025-08-29T15:00:46.151+01:00"}
---

<a href="https://anapoly.co.uk/labs">Anapoly Notebook</a>
# A digital garden for ideas about shaping Human-AI interaction

*digital garden: a place to share and develop ideas in a flexible, interconnected, and constantly updated space.*  
*ideas develop from seed → growing → well-formed → fruitful → retired*

Transparency label: human only

---

Maggie Appleton describes [[Digital Garden/digital gardening\|digital gardening]] as the nurturing of ideas, connecting them through contextual association rather than publication date. Beginning as seeds, the ideas grow and evolve through thinking. Some prove fruitful, others less so. 

The first seed in this garden was planted during a philosophical exchange with Giles Freathy. We were talking about the temptation for us to outsource our thinking to AI. This risks us losing our critical thinking skills, and the judgement and decision-making abilities which depend on that. We need a better understanding of the problem with Human-AI interaction. Perhaps we could set up  [[Digital Garden/Exploring a collaboration\|a collaboration]] to study it?

But what is AI, and how do we interact with it? By AI, we usually mean large language models. Though not yet intelligent, they can seem so. This in itself is a concern. <a href="https://www.kozyr.com/about">Cassie Kozyrkov</a> explains why we should worry about AI psychosis in <a href="https://substack.com/home/post/p-171599460">this Substack post</a>. 

> _“Some people reportedly believe their AI is God, or a fictional character, or fall in love with it to the point of absolute distraction. Meanwhile those actually working on the science of consciousness tell me they are inundated with queries from people asking ‘is my AI conscious?’ What does it mean if it is? Is it ok that I love it? The trickle of emails is turning into a flood. A group of scholars have even created a supportive [guide](https://whenaiseemsconscious.org/) for those falling into the trap.”_
> 
> “Simply put, my central worry is that many people will start to believe in the illusion of AIs as conscious entities so strongly that they’ll soon advocate for AI rights, [model welfare](https://arxiv.org/abs/2411.00986) and even AI citizenship.”

 The second seed in this garden arises from the need for there to be an ethos of caring about how the Human-AI relationship evolves. We need to think carefully about how [[Digital Garden/Values, Ethics, Culture, & Ethos\|values, ethics, culture, and ethos]] fit together.
 
It's estimated that approaching a billion people now use AI in one way or another. Most commonly, this is through a chat interface such as that offered by ChatGPT, which reportedly has nearly 500 million users. We interact with the "chatbot" through its [[Digital Garden/What is context\|context]], which is much more than just a chat window. If we choose carefully what we put into the AI's context, we can turn ourselves from passive users of what it has to offer into active managers of its behaviour. Alejandro Piad Morffis suggests <a href="https://blog.apiad.net/p/a-pragmatic-workflow-for-technical?utm_source=publication-search">one way to do this when writing</a>. Another approach is [[Digital Garden/Goal-Directed Context Management v1\|Goal-Directed Context Management]] which applies instructions and prompts progressively, each set being tightly focused on a specific stage of work. Both approaches can be adapted to suit almost any scenario. They enables us - if we so choose - to configure the AI so that it enhances our capacity to think, rather than letting it do our thinking for us. That is a seed worth nurturing. 

But as well as managing the AI’s behaviour, we need to manage our own. Knowledge workers, in particular, need to capture, learn from, enrich, and create ideas. We are encouraged to use a personal knowledge management system, sometimes called a "second brain", to help us with this. I had been experimenting with <a href="https://obsidian.md">Obsidian</a> for that purpose, but I've come round to Joan Westenberg's <a href="https://www.joanwestenberg.com/p/i-deleted-my-second-brain">way of thinking about it</a> when she deleted her second brain:

> "I don’t want to manage knowledge. I want to live it. I still love Obsidian. And I’m planning on using it again. From scratch. And with a deeper level of curation and care - not as a second brain, but as a workspace for the one I already have."

I have moved nearly everything in my Obsidian vault into an archive folder and begun again. The third seed in this garden, therefore, concerns a *workspace for the brain*. The workspace needs to be an idea factory. But rather than an assembly line, we can think of it as a network of interconnected ideas at varying levels of maturity and complexity.  It must let us bring in other people's thinking, helping us capture ideas and add them to our existing network of ideas. These ideas must be discoverable, whilst retaining enough context for each idea to be understandable.  We must be able to draw on these ideas in order to create new ones and remix them into original thinking; and it must be easy for us to share that thinking. Above all, our *thinking space* must suit the way we think; it should be structured and organised - tailored - for each of us individually. 
 
There is scope for AI technology to enhance our thinking in that workspace without intruding on it. For example, the ideas held in the network can be embedded into a [[20 - Archive 2025-08-27/07 - Atoms/vector database\|vector database]], similar to the way an AI’s knowledge is stored. That enables the similarities amongst widely dispersed ideas - the [[20 - Archive 2025-08-27/07 - Atoms/semantic connection\|semantic connections]] - to be highlighted for us to think about.  It enables us, also, to search the network not just for the presence of words, but for ideas with similar meanings to the words in our search term. 

We can take this a step further by inviting an AI into our *thinking space*. If we connect the AI to the vector database mentioned above, we will be able to use it in all sorts of interesting ways to explore and develop our thinking. The danger here, of course, is the temptation to let the AI do our thinking for us. This is where [[Digital Garden/Goal-Directed Context Management v1\|context management]] can help. We will have to configure the AI's behaviour to reduce that danger. We can give it freedom to find things in the network, to point us in useful directions, to critique our ideas, to highlight interesting relationships amongst them, and to question the logic of our arguments. Equally, we can instruct it not to offer its own ideas or solutions to the problems we are thinking about. We must configure it to guide us up the knowledge mountain, not carry us to the top. 

It remains to be seen if that vision can be put into practice. It will require an ethos of caring about how the Human-AI relationship evolves. 

---

## Seeds

What is the problem with Human-AI interaction?
Ethos of caring about how the Human-AI relationship evolves
Managing AI behaviour
Managing our own behaviour
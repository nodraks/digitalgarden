---
{"dg-publish":true,"permalink":"/digital-garden/digital-garden/","tags":["gardenEntry"],"created":"2025-08-11T21:46:53.866+01:00","updated":"2025-08-27T23:57:54.274+01:00"}
---

<a href="https://anapoly.co.uk/labs">Anapoly Notebook</a>
# A digital garden for ideas about shaping Human-AI interaction

*digital garden: a place to share and develop ideas in a flexible, interconnected, and constantly updated space.*  
*ideas develop from seed → growing → well-formed → fruitful → retired*

Transparency label: human only

---

Maggie Appleton describes [[Digital Garden/digital gardening\|digital gardening]] as the nurturing of ideas, connecting them through contextual association rather than publication date. Beginning as seeds, the ideas grow and evolve through thinking. Some prove fruitful, others less so. 

The first seed in this garden was planted during a philosophical exchange with Giles Freathy. We were talking about the temptation for us to outsource our thinking to AI, which risks us losing our critical thinking skills and the judgement and decision-making abilities which depend on that. We need a better understanding of [[Digital Garden/The Problem with Human-AI Interaction\|the problem with Human-AI interaction]]. Perhaps we could [[20 - Archive 2025-08-27/07 - Atoms/Exploring a collaboration\|explore a collaboration]] to study it.

But what is AI, and how do we interact with it? By AI, we usually mean large language models. Though not yet intelligent, they can seem so. This in itself is a concern. <a href="https://www.kozyr.com/about">Cassie Kozyrkov</a> explains why we should worry about AI psychosis in <a href="https://substack.com/home/post/p-171599460">this Substack post</a>. 

> _“Some people reportedly believe their AI is God, or a fictional character, or fall in love with it to the point of absolute distraction. Meanwhile those actually working on the science of consciousness tell me they are inundated with queries from people asking ‘is my AI conscious?’ What does it mean if it is? Is it ok that I love it? The trickle of emails is turning into a flood. A group of scholars have even created a supportive [guide](https://whenaiseemsconscious.org/) for those falling into the trap.”_
> 
> “Simply put, my central worry is that many people will start to believe in the illusion of AIs as conscious entities so strongly that they’ll soon advocate for AI rights, [model welfare](https://arxiv.org/abs/2411.00986) and even AI citizenship.”

 The second seed arises from the need for there to be an ethos of caring about how the Human-AI relationship evolves. We need to think carefully about how [[Digital Garden/Values, Ethics, Culture, & Ethos\|values, ethics, culture, and ethos]] fit together.
 
- **Values**, our moral compass;
- **Ethics**, how we apply them;
- **Culture**, where values and ethics live;
- **Ethos**, the vibe or spirit of that culture.

It's estimated that approaching a billion people now use AI in one way or another. Most commonly, this is through a chat interface such as that offered by ChatGPT, which reportedly has nearly 500 million users. We interact with the "chatbot" through its [[Digital Garden/What is context\|context]], which is much more than just a chat window. If we choose carefully what we put into the AI's context, we can turn ourselves from passive users of what it has to offer into active managers of its behaviour. [[Digital Garden/Goal-Directed Context Management v1\|Goal-Directed Context Management]] explains how to do that when producing a report or other knowledge-based product. But the approach can be adapted to suit almost any scenario. It enables us - if we so choose - to configure the AI so that it enhances our capacity to think, rather than letting it do our thinking for us. That is a seed worth nurturing. 

As well as managing the AI’s behaviour, we need to manage our own. Knowledge workers, in particular, need to capture, learn from, enrich, and create ideas. We are encouraged to use a personal knowledge management system, sometimes called a "second brain", to help us with this. I had been experimenting with Obsidian for that purpose, but I've come round to Joan Westenberg's way of thinking about it (see"<a href="https://www.joanwestenberg.com/p/i-deleted-my-second-brain">I deleted my second brain</a>"): 

> "I don’t want to manage knowledge. I want to live it. I still love Obsidian. And I’m planning on using it again. From scratch. And with a deeper level of curation and care - not as a second brain, but as a workspace for the one I already have."

While this workspace is an idea factory, it does not have an assembly line. Instead, it is a network of interconnected ideas at varying levels of complexity, with the inherently greater capacity that affords. This *thinking network* should be structured and organised accordingly, and tailored individually to suit the way we process ideas. 

AI must not be allowed to intrude on the *thinking network*. There is scope, however, for AI technology to enhance the thinking process without intruding. For example, the ideas held in the network can be embedded in a [[20 - Archive 2025-08-27/07 - Atoms/vector database\|vector database]], similar to the way an AI’s knowledge is stored. That enables the similarities amongst widely dispersed ideas - the [[20 - Archive 2025-08-27/07 - Atoms/semantic connection\|semantic connections]] - to be highlighted and thereby stimulate creative thinking.  

We can take this a step further by bringing in an AI. If we connect the AI to our *thinking network*, we will be able to use it in all sorts of interesting ways to explore and develop ideas. This has the potential to boost creativity greatly. 

A danger from letting AI into our thinking network is that we will begin to let it do our thinking for us. This is where [[Digital Garden/Goal-Directed Context Management v1\|context management]] comes into play. We will have to configure the AI's behaviour to reduce that danger. We can give it freedom to find things in the network, to point us in useful directions, to critique our ideas, to highlight interesting relationships amongst them, and to question the logic of our arguments. Equally, we can instruct it not to offer its own ideas or solutions to the problems we am thinking about. We must configure it to guide us up the knowledge mountain, not carry us to the top. 

It will be interesting to see how well that vision can be put into practice. It will require an ethos of caring about how the Human-AI relationship evolves. 

---

## Seeds

Ethos of caring about how the Human-AI relationship evolves
What is the problem with Human-AI interaction?
Managing AI behaviour
Managing our own behaviour